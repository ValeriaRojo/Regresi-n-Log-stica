{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as special\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>license</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3781</td>\n",
       "      <td>https://www.airbnb.com/rooms/3781</td>\n",
       "      <td>20241220045258</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>previous scrape</td>\n",
       "      <td>HARBORSIDE-Walk to subway</td>\n",
       "      <td>Fully separate apartment in a two apartment bu...</td>\n",
       "      <td>Mostly quiet ( no loud music, no crowed sidewa...</td>\n",
       "      <td>https://a0.muscache.com/pictures/24670/b2de044...</td>\n",
       "      <td>4804</td>\n",
       "      <td>...</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5506</td>\n",
       "      <td>https://www.airbnb.com/rooms/5506</td>\n",
       "      <td>20241220045258</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>** Fort Hill Inn Private! Minutes to center!**</td>\n",
       "      <td>Private guest room with private bath, You do n...</td>\n",
       "      <td>Peaceful, Architecturally interesting, histori...</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>8229</td>\n",
       "      <td>...</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.76</td>\n",
       "      <td>STR-490093</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10986</td>\n",
       "      <td>https://www.airbnb.com/rooms/10986</td>\n",
       "      <td>20241220045258</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>previous scrape</td>\n",
       "      <td>North End (Waterfront area)  CLOSE TO MGH &amp; SU...</td>\n",
       "      <td>Chic furnished studio apartment is located on ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/46994/567b606...</td>\n",
       "      <td>38997</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29765</td>\n",
       "      <td>https://www.airbnb.com/rooms/29765</td>\n",
       "      <td>20241220045258</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Moroccan Decor Suite</td>\n",
       "      <td>The apartment is a unique space that offers a ...</td>\n",
       "      <td>Boston's oldest and most historic neighborhood...</td>\n",
       "      <td>https://a0.muscache.com/pictures/621420/77d899...</td>\n",
       "      <td>128280</td>\n",
       "      <td>...</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.94</td>\n",
       "      <td>STR-454024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45987</td>\n",
       "      <td>https://www.airbnb.com/rooms/45987</td>\n",
       "      <td>20241220045258</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Garden Studio</td>\n",
       "      <td>Light and spacious garden studio apartment has...</td>\n",
       "      <td>Historical and safe.</td>\n",
       "      <td>https://a0.muscache.com/pictures/7a7d6642-f493...</td>\n",
       "      <td>205107</td>\n",
       "      <td>...</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.53</td>\n",
       "      <td>STR-409822</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                         listing_url       scrape_id last_scraped  \\\n",
       "0   3781   https://www.airbnb.com/rooms/3781  20241220045258   2024-12-20   \n",
       "1   5506   https://www.airbnb.com/rooms/5506  20241220045258   2024-12-20   \n",
       "2  10986  https://www.airbnb.com/rooms/10986  20241220045258   2024-12-20   \n",
       "3  29765  https://www.airbnb.com/rooms/29765  20241220045258   2024-12-20   \n",
       "4  45987  https://www.airbnb.com/rooms/45987  20241220045258   2024-12-20   \n",
       "\n",
       "            source                                               name  \\\n",
       "0  previous scrape                          HARBORSIDE-Walk to subway   \n",
       "1      city scrape     ** Fort Hill Inn Private! Minutes to center!**   \n",
       "2  previous scrape  North End (Waterfront area)  CLOSE TO MGH & SU...   \n",
       "3      city scrape                               Moroccan Decor Suite   \n",
       "4      city scrape                                      Garden Studio   \n",
       "\n",
       "                                         description  \\\n",
       "0  Fully separate apartment in a two apartment bu...   \n",
       "1  Private guest room with private bath, You do n...   \n",
       "2  Chic furnished studio apartment is located on ...   \n",
       "3  The apartment is a unique space that offers a ...   \n",
       "4  Light and spacious garden studio apartment has...   \n",
       "\n",
       "                               neighborhood_overview  \\\n",
       "0  Mostly quiet ( no loud music, no crowed sidewa...   \n",
       "1  Peaceful, Architecturally interesting, histori...   \n",
       "2                                                NaN   \n",
       "3  Boston's oldest and most historic neighborhood...   \n",
       "4                               Historical and safe.   \n",
       "\n",
       "                                         picture_url  host_id  ...  \\\n",
       "0  https://a0.muscache.com/pictures/24670/b2de044...     4804  ...   \n",
       "1  https://a0.muscache.com/pictures/miso/Hosting-...     8229  ...   \n",
       "2  https://a0.muscache.com/pictures/46994/567b606...    38997  ...   \n",
       "3  https://a0.muscache.com/pictures/621420/77d899...   128280  ...   \n",
       "4  https://a0.muscache.com/pictures/7a7d6642-f493...   205107  ...   \n",
       "\n",
       "  review_scores_communication review_scores_location review_scores_value  \\\n",
       "0                        4.96                   4.85                4.88   \n",
       "1                        4.89                   4.56                4.76   \n",
       "2                        5.00                   5.00                4.00   \n",
       "3                        4.97                   4.81                4.94   \n",
       "4                        4.71                   4.83                4.53   \n",
       "\n",
       "      license instant_bookable calculated_host_listings_count  \\\n",
       "0         NaN                0                              1   \n",
       "1  STR-490093                0                             10   \n",
       "2         NaN                0                             13   \n",
       "3  STR-454024                0                              1   \n",
       "4  STR-409822                0                              1   \n",
       "\n",
       "  calculated_host_listings_count_entire_homes  \\\n",
       "0                                           1   \n",
       "1                                          10   \n",
       "2                                          13   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "\n",
       "  calculated_host_listings_count_private_rooms  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   calculated_host_listings_count_shared_rooms reviews_per_month  \n",
       "0                                            0              0.23  \n",
       "1                                            0              0.69  \n",
       "2                                            0              0.09  \n",
       "3                                            0              0.58  \n",
       "4                                            0              0.81  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cargar archivo desde seaborn \n",
    "df=pd.read_csv('Boston_Limpio_Procesado.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar archivo csv desde seaboarn\n",
    "#df=sns.load_dataset(name='titanic')\n",
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghseb\\AppData\\Local\\Temp\\ipykernel_21744\\2761572045.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"bfill\")\n",
      "C:\\Users\\ghseb\\AppData\\Local\\Temp\\ipykernel_21744\\2761572045.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "# Relleno de valores nulos \n",
    "\n",
    "df = df.fillna(method=\"bfill\")\n",
    "df = df.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name',\n",
      "       'description', 'neighborhood_overview', 'picture_url', 'host_id',\n",
      "       'host_url', 'host_name', 'host_since', 'host_location', 'host_about',\n",
      "       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
      "       'host_is_superhost', 'host_thumbnail_url', 'host_picture_url',\n",
      "       'host_neighbourhood', 'host_listings_count',\n",
      "       'host_total_listings_count', 'host_verifications',\n",
      "       'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n",
      "       'neighbourhood_cleansed', 'latitude', 'longitude', 'property_type',\n",
      "       'room_type', 'accommodates', 'bathrooms', 'bathrooms_text', 'bedrooms',\n",
      "       'beds', 'amenities', 'price', 'minimum_nights', 'maximum_nights',\n",
      "       'minimum_minimum_nights', 'maximum_minimum_nights',\n",
      "       'minimum_maximum_nights', 'maximum_maximum_nights',\n",
      "       'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'has_availability',\n",
      "       'availability_30', 'availability_60', 'availability_90',\n",
      "       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n",
      "       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review',\n",
      "       'last_review', 'review_scores_rating', 'review_scores_accuracy',\n",
      "       'review_scores_cleanliness', 'review_scores_checkin',\n",
      "       'review_scores_communication', 'review_scores_location',\n",
      "       'review_scores_value', 'license', 'instant_bookable',\n",
      "       'calculated_host_listings_count',\n",
      "       'calculated_host_listings_count_entire_homes',\n",
      "       'calculated_host_listings_count_private_rooms',\n",
      "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# AsegÃºrate de que tienes un DataFrame llamado 'df'\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'scrape_id', 'host_id', 'host_is_superhost',\n",
      "       'host_listings_count', 'host_total_listings_count',\n",
      "       'host_has_profile_pic', 'host_identity_verified', 'latitude',\n",
      "       'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'price',\n",
      "       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
      "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
      "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
      "       'maximum_nights_avg_ntm', 'availability_30', 'availability_60',\n",
      "       'availability_90', 'availability_365', 'number_of_reviews',\n",
      "       'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
      "       'review_scores_rating', 'review_scores_accuracy',\n",
      "       'review_scores_cleanliness', 'review_scores_checkin',\n",
      "       'review_scores_communication', 'review_scores_location',\n",
      "       'review_scores_value', 'instant_bookable',\n",
      "       'calculated_host_listings_count',\n",
      "       'calculated_host_listings_count_entire_homes',\n",
      "       'calculated_host_listings_count_private_rooms',\n",
      "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Imprimir las columnas que son de tipo numÃ©rico\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "print(numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].astype(str).str.replace(r'[\\$,]', '', regex=True)\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    135.0\n",
      "1    112.0\n",
      "2    135.0\n",
      "3    243.0\n",
      "4    100.0\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['price'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertimos string a tipos numÃ©ricos\n",
    "#df['host_is_superhost'] = df['host_is_superhost'].replace({'f': 0, 't': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir variables categÃ³ricas a numÃ©ricas\n",
    "#df['host_is_superhost'] = df['host_is_superhost'].map({'f': 0, 't': 1})\n",
    "#df['host_has_profile_pic'] = df['host_has_profile_pic'].map({'f': 0, 't': 1})\n",
    "#df['host_identity_verified'] = df['host_identity_verified'].map({'f': 0, 't': 1})\n",
    "#df['instant_bookable'] = df['instant_bookable'].map({'f': 0, 't': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    1.0\n",
      "5    1.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    1.0\n",
      "9    1.0\n",
      "Name: host_is_superhost, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['host_is_superhost'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresiÃ³n logÃ­stica\n",
    "#Vars_Indep = df[['pclass', 'age', 'fare']]\n",
    "#Var_Dep = df['alive']\n",
    "Vars_Indep1= df[['price', 'accommodates']]\n",
    "Var_Dep1= df['host_is_superhost']\n",
    "\n",
    "# Caso 1\n",
    "Vars_Indep2 = df[['price', 'accommodates']]\n",
    "Var_Dep2 = df['host_is_superhost']\n",
    "\n",
    "# Caso 2\n",
    "Vars_Indep3 = df[['bedrooms', 'beds']]\n",
    "Var_Dep3 = df['instant_bookable']\n",
    "\n",
    "# Caso 3\n",
    "Vars_Indep4 = df[['price', 'availability_90']]\n",
    "Var_Dep4 = df['host_identity_verified']\n",
    "\n",
    "# Caso 4\n",
    "Vars_Indep5 = df[['minimum_nights', 'reviews_per_month']]\n",
    "Var_Dep5 = df['host_is_superhost']\n",
    "\n",
    "# Caso 5\n",
    "Vars_Indep6 = df[['accommodates', 'bathrooms']]\n",
    "Var_Dep6 = df['instant_bookable']\n",
    "\n",
    "# Caso 6\n",
    "Vars_Indep7 = df[['price', 'number_of_reviews']]\n",
    "Var_Dep7 = df['host_identity_verified']\n",
    "\n",
    "# Caso 7\n",
    "Vars_Indep8 = df[['beds', 'availability_30']]\n",
    "Var_Dep8 = df['host_is_superhost']\n",
    "\n",
    "# Caso 8\n",
    "Vars_Indep9 = df[['price', 'review_scores_rating']]\n",
    "Var_Dep9 = df['instant_bookable']\n",
    "\n",
    "# Caso 9\n",
    "Vars_Indep10 = df[['reviews_per_month', 'bedrooms']]\n",
    "Var_Dep10 = df['host_identity_verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinimos las variables\n",
    "X = Vars_Indep1\n",
    "y = Var_Dep1\n",
    "x2 = Vars_Indep2\n",
    "y2 = Var_Dep2           \n",
    "x3 = Vars_Indep3\n",
    "y3 = Var_Dep3\n",
    "x4 = Vars_Indep4\n",
    "y4 = Var_Dep4\n",
    "x5 = Vars_Indep5\n",
    "y5 = Var_Dep5\n",
    "x6 = Vars_Indep6\n",
    "y6 = Var_Dep6\n",
    "x7 = Vars_Indep7\n",
    "y7 = Var_Dep7\n",
    "x8 = Vars_Indep8\n",
    "y8 = Var_Dep8\n",
    "x9 = Vars_Indep9\n",
    "y9 = Var_Dep9\n",
    "x10 = Vars_Indep10\n",
    "y10 = Var_Dep10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "\n",
    "\n",
    "# Dividir cada conjunto de variables independientes y dependientes\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.3, random_state=None)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=0.3, random_state=None)\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(x4, y4, test_size=0.3, random_state=None)\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(x5, y5, test_size=0.3, random_state=None)\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(x6, y6, test_size=0.3, random_state=None)\n",
    "X7_train, X7_test, y7_train, y7_test = train_test_split(x7, y7, test_size=0.3, random_state=None)\n",
    "X8_train, X8_test, y8_train, y8_test = train_test_split(x8, y8, test_size=0.3, random_state=None)\n",
    "X9_train, X9_test, y9_train, y9_test = train_test_split(x9, y9, test_size=0.3, random_state=None)\n",
    "X10_train, X10_test, y10_train, y10_test = train_test_split(x10, y10, test_size=0.3, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se escalan todos los datos\n",
    "escalar = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos\n",
    "#X_train = escalar.fit_transform(X_train)\n",
    "#X_test = escalar.transform(X_test)\n",
    "\n",
    "# Escalamos cada conjunto de datos (X_train y X_test) para las 10 variables\n",
    "# --- Conjunto 1 ---\n",
    "X1_train = escalar.fit_transform(X1_train)  \n",
    "X1_test = escalar.transform(X1_test)       \n",
    "\n",
    "# --- Conjunto 2 ---\n",
    "X2_train = escalar.fit_transform(X2_train)\n",
    "X2_test = escalar.transform(X2_test)\n",
    "\n",
    "# --- Conjunto 3 ---\n",
    "X3_train = escalar.fit_transform(X3_train)\n",
    "X3_test = escalar.transform(X3_test)\n",
    "\n",
    "# --- Conjunto 4 ---\n",
    "X4_train = escalar.fit_transform(X4_train)\n",
    "X4_test = escalar.transform(X4_test)\n",
    "\n",
    "# --- Conjunto 5 ---\n",
    "X5_train = escalar.fit_transform(X5_train)\n",
    "X5_test = escalar.transform(X5_test)\n",
    "\n",
    "# --- Conjunto 6 ---\n",
    "X6_train = escalar.fit_transform(X6_train)\n",
    "X6_test = escalar.transform(X6_test)\n",
    "\n",
    "# --- Conjunto 7 ---\n",
    "X7_train = escalar.fit_transform(X7_train)\n",
    "X7_test = escalar.transform(X7_test)\n",
    "\n",
    "# --- Conjunto 8 ---\n",
    "X8_train = escalar.fit_transform(X8_train)\n",
    "X8_test = escalar.transform(X8_test)\n",
    "\n",
    "# --- Conjunto 9 ---\n",
    "X9_train = escalar.fit_transform(X9_train)\n",
    "X9_test = escalar.transform(X9_test)\n",
    "\n",
    "# --- Conjunto 10 ---\n",
    "X10_train = escalar.fit_transform(X10_train)\n",
    "X10_test = escalar.transform(X10_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entremanos el modelo   \n",
    "#algoritmo.fit(X_train, y_train) \n",
    "\n",
    "# Entrenamos los 10 modelos uno por uno:\n",
    "\n",
    "# Modelo 1\n",
    "algoritmo.fit(X1_train, y1_train)\n",
    "\n",
    "# Modelo 2\n",
    "algoritmo.fit(X2_train, y2_train)\n",
    "\n",
    "# Modelo 3\n",
    "algoritmo.fit(X3_train, y3_train)\n",
    "\n",
    "# Modelo 4\n",
    "algoritmo.fit(X4_train, y4_train)\n",
    "\n",
    "# Modelo 5\n",
    "algoritmo.fit(X5_train, y5_train)\n",
    "\n",
    "# Modelo 6\n",
    "algoritmo.fit(X6_train, y6_train)\n",
    "\n",
    "# Modelo 7\n",
    "algoritmo.fit(X7_train, y7_train)\n",
    "\n",
    "# Modelo 8\n",
    "algoritmo.fit(X8_train, y8_train)\n",
    "\n",
    "# Modelo 9\n",
    "algoritmo.fit(X9_train, y9_train)\n",
    "\n",
    "# Modelo 10\n",
    "algoritmo.fit(X10_train, y10_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del conjunto de entrenamiento: (825, 2)\n",
      "Dimensiones de X1_test: (354, 2)\n",
      "Dimensiones de X2_test: (354, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensiones del conjunto de entrenamiento:\", X1_train.shape)\n",
    "print(\"Dimensiones de X1_test:\", X1_test.shape)\n",
    "print(\"Dimensiones de X2_test:\", X2_test.shape)\n",
    "# Repite para los demÃ¡s conjuntos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona las primeras 2 columnas de cada conjunto de prueba\n",
    "#X1_test = X1_test[:, :2]\n",
    "#X2_test = X2_test[:, :2]\n",
    "#X3_test = X3_test[:, :2]\n",
    "#X4_test = X4_test[:, :2]\n",
    "#X5_test = X5_test[:, :2]\n",
    "#X6_test = X6_test[:, :2]\n",
    "#X7_test = X7_test[:, :2]\n",
    "#X8_test = X8_test[:, :2]\n",
    "#X9_test = X9_test[:, :2]\n",
    "#X10_test = X10_test[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones Modelo 1: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicciones Modelo 2: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicciones Modelo 3: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicciones Modelo 4: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicciones Modelo 5: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicciones Modelo 6: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicciones Modelo 7: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicciones Modelo 8: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicciones Modelo 9: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicciones Modelo 10: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#realizamos una predicciÃ³n  \n",
    "#y_pred = algoritmo.predict(X_test)\n",
    "#y_pred\n",
    "\n",
    "\n",
    "# PredicciÃ³n Modelo 1\n",
    "y1_pred = algoritmo.predict(X1_test)\n",
    "\n",
    "# PredicciÃ³n Modelo 2\n",
    "y2_pred = algoritmo.predict(X2_test)\n",
    "\n",
    "# PredicciÃ³n Modelo 3\n",
    "y3_pred = algoritmo.predict(X3_test)\n",
    "\n",
    "# PredicciÃ³n Modelo 4\n",
    "y4_pred = algoritmo.predict(X4_test)\n",
    "\n",
    "# PredicciÃ³n Modelo 5\n",
    "y5_pred = algoritmo.predict(X5_test)\n",
    "\n",
    "# PredicciÃ³n Modelo 6\n",
    "y6_pred = algoritmo.predict(X6_test)\n",
    "\n",
    "# PredicciÃ³n Modelo 7\n",
    "y7_pred = algoritmo.predict(X7_test)\n",
    "\n",
    "# PredicciÃ³n Modelo 8\n",
    "y8_pred = algoritmo.predict(X8_test)\n",
    "\n",
    "# PredicciÃ³n Modelo 9\n",
    "y9_pred = algoritmo.predict(X9_test)\n",
    "\n",
    "# PredicciÃ³n Modelo 10\n",
    "y10_pred = algoritmo.predict(X10_test)\n",
    "\n",
    "# Imprimir las predicciones de cada modelo\n",
    "print(\"Predicciones Modelo 1:\", y1_pred)    \n",
    "print(\"Predicciones Modelo 2:\", y2_pred)\n",
    "print(\"Predicciones Modelo 3:\", y3_pred)\n",
    "print(\"Predicciones Modelo 4:\", y4_pred)\n",
    "print(\"Predicciones Modelo 5:\", y5_pred)\n",
    "print(\"Predicciones Modelo 6:\", y6_pred)\n",
    "print(\"Predicciones Modelo 7:\", y7_pred)\n",
    "print(\"Predicciones Modelo 8:\", y8_pred)\n",
    "print(\"Predicciones Modelo 9:\", y9_pred)\n",
    "print(\"Predicciones Modelo 10:\", y10_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convierte las etiquetas reales a nÃºmeros\n",
    "#y1_test = [0 if label == 'f' else 1 for label in y1_test]\n",
    "#y2_test = [0 if label == 'f' else 1 for label in y2_test]\n",
    "#y3_test = [0 if label == 'f' else 1 for label in y3_test]\n",
    "#y4_test = [0 if label == 'f' else 1 for label in y4_test]\n",
    "##y5_test = [0 if label == 'f' else 1 for label in y5_test]\n",
    "#y6_test = [0 if label == 'f' else 1 for label in y6_test]\n",
    "#y7_test = [0 if label == 'f' else 1 for label in y7_test]\n",
    "#y8_test = [0 if label == 'f' else 1 for label in y8_test]\n",
    "#y9_test = [0 if label == 'f' else 1 for label in y9_test]\n",
    "#y10_test = [0 if label == 'f' else 1 for label in y10_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas reales (y1_test): 551     1.0\n",
      "296     0.0\n",
      "1013    0.0\n",
      "321     1.0\n",
      "393     1.0\n",
      "394     0.0\n",
      "128     1.0\n",
      "629     0.0\n",
      "453     0.0\n",
      "14      0.0\n",
      "Name: host_is_superhost, dtype: float64\n",
      "Etiquetas predichas (y1_pred): [1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Etiquetas reales (y1_test):\", y1_test[:10])\n",
    "print(\"Etiquetas predichas (y1_pred):\", y1_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de ConfusiÃ³n Modelo 1:\n",
      "[[  0 223]\n",
      " [  0 131]]\n",
      "\n",
      "Matriz de ConfusiÃ³n Modelo 2:\n",
      "[[  0 230]\n",
      " [  0 124]]\n",
      "\n",
      "Matriz de ConfusiÃ³n Modelo 3:\n",
      "[[  0 221]\n",
      " [  0 133]]\n",
      "\n",
      "Matriz de ConfusiÃ³n Modelo 4:\n",
      "[[  0  36]\n",
      " [  0 318]]\n",
      "\n",
      "Matriz de ConfusiÃ³n Modelo 5:\n",
      "[[  0 220]\n",
      " [  0 134]]\n",
      "\n",
      "Matriz de ConfusiÃ³n Modelo 6:\n",
      "[[  0 229]\n",
      " [  0 125]]\n",
      "\n",
      "Matriz de ConfusiÃ³n Modelo 7:\n",
      "[[  0  36]\n",
      " [  0 318]]\n",
      "\n",
      "Matriz de ConfusiÃ³n Modelo 8:\n",
      "[[  0 229]\n",
      " [  0 125]]\n",
      "\n",
      "Matriz de ConfusiÃ³n Modelo 9:\n",
      "[[  0 234]\n",
      " [  0 120]]\n",
      "\n",
      "Matriz de ConfusiÃ³n Modelo 10:\n",
      "[[  0  37]\n",
      " [  0 317]]\n"
     ]
    }
   ],
   "source": [
    "#verifico la matriz de confusiÃ³n\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#matriz = confusion_matrix(y_test, y_pred)\n",
    "#print('Matriz de ConfusiÃ³n:')\n",
    "#print(matriz)\n",
    "\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Matriz de confusiÃ³n para cada modelo:\n",
    "\n",
    "# --- Modelo 1 ---\n",
    "matriz1 = confusion_matrix(y1_test, y1_pred)\n",
    "print('\\nMatriz de ConfusiÃ³n Modelo 1:')\n",
    "print(matriz1)\n",
    "\n",
    "# --- Modelo 2 ---\n",
    "matriz2 = confusion_matrix(y2_test, y2_pred)\n",
    "print('\\nMatriz de ConfusiÃ³n Modelo 2:')\n",
    "print(matriz2)\n",
    "\n",
    "# --- Modelo 3 ---\n",
    "matriz3 = confusion_matrix(y3_test, y3_pred)\n",
    "print('\\nMatriz de ConfusiÃ³n Modelo 3:')\n",
    "print(matriz3)\n",
    "\n",
    "# --- Modelo 4 ---\n",
    "matriz4 = confusion_matrix(y4_test, y4_pred)\n",
    "print('\\nMatriz de ConfusiÃ³n Modelo 4:')\n",
    "print(matriz4)\n",
    "\n",
    "# --- Modelo 5 ---\n",
    "matriz5 = confusion_matrix(y5_test, y5_pred)\n",
    "print('\\nMatriz de ConfusiÃ³n Modelo 5:')\n",
    "print(matriz5)\n",
    "\n",
    "# --- Modelo 6 ---\n",
    "matriz6 = confusion_matrix(y6_test, y6_pred)\n",
    "print('\\nMatriz de ConfusiÃ³n Modelo 6:')\n",
    "print(matriz6)\n",
    "\n",
    "# --- Modelo 7 ---\n",
    "matriz7 = confusion_matrix(y7_test, y7_pred)\n",
    "print('\\nMatriz de ConfusiÃ³n Modelo 7:')\n",
    "print(matriz7)\n",
    "\n",
    "# --- Modelo 8 ---\n",
    "matriz8 = confusion_matrix(y8_test, y8_pred)\n",
    "print('\\nMatriz de ConfusiÃ³n Modelo 8:')\n",
    "print(matriz8)\n",
    "\n",
    "# --- Modelo 9 ---\n",
    "matriz9 = confusion_matrix(y9_test, y9_pred)\n",
    "print('\\nMatriz de ConfusiÃ³n Modelo 9:')\n",
    "print(matriz9)\n",
    "\n",
    "# --- Modelo 10 ---\n",
    "matriz10 = confusion_matrix(y10_test, y10_pred)\n",
    "print('\\nMatriz de ConfusiÃ³n Modelo 10:')\n",
    "print(matriz10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Matriz de ConfusiÃ³n Modelo 1 (Umbral=0.3) ---\n",
      "[[  0   0 222   1]\n",
      " [  0   0 131   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n",
      "\n",
      "--- Matriz de ConfusiÃ³n Modelo 2 (Umbral=0.3) ---\n",
      "[[  0   0 230]\n",
      " [  0   0 124]\n",
      " [  0   0   0]]\n",
      "\n",
      "--- Matriz de ConfusiÃ³n Modelo 3 (Umbral=0.3) ---\n",
      "[[  0   0 221]\n",
      " [  0   0 133]\n",
      " [  0   0   0]]\n",
      "\n",
      "--- Matriz de ConfusiÃ³n Modelo 4 (Umbral=0.3) ---\n",
      "[[  0   0  36]\n",
      " [  0   0 318]\n",
      " [  0   0   0]]\n",
      "\n",
      "--- Matriz de ConfusiÃ³n Modelo 5 (Umbral=0.3) ---\n",
      "[[  0   0 220]\n",
      " [  0   0 134]\n",
      " [  0   0   0]]\n",
      "\n",
      "--- Matriz de ConfusiÃ³n Modelo 6 (Umbral=0.3) ---\n",
      "[[  0   0 229]\n",
      " [  0   0 125]\n",
      " [  0   0   0]]\n",
      "\n",
      "--- Matriz de ConfusiÃ³n Modelo 7 (Umbral=0.3) ---\n",
      "[[  0   0  36]\n",
      " [  0   0 318]\n",
      " [  0   0   0]]\n",
      "\n",
      "--- Matriz de ConfusiÃ³n Modelo 8 (Umbral=0.3) ---\n",
      "[[  0   0 229]\n",
      " [  0   0 125]\n",
      " [  0   0   0]]\n",
      "\n",
      "--- Matriz de ConfusiÃ³n Modelo 9 (Umbral=0.3) ---\n",
      "[[  0   0 234]\n",
      " [  0   0 120]\n",
      " [  0   0   0]]\n",
      "\n",
      "--- Matriz de ConfusiÃ³n Modelo 10 (Umbral=0.3) ---\n",
      "[[  0   0  37]\n",
      " [  0   0 317]\n",
      " [  0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Configura el modelo con balanceo de clases y ajuste de umbral\n",
    "modelo = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "\n",
    "# Lista de tus pares (X_train, X_test, y_train, y_test) para los 10 modelos\n",
    "datos_modelos = [\n",
    "    (X1_train, X1_test, y1_train, y1_test),\n",
    "    (X2_train, X2_test, y2_train, y2_test),\n",
    "    (X3_train, X3_test, y3_train, y3_test),\n",
    "    (X4_train, X4_test, y4_train, y4_test),\n",
    "    (X5_train, X5_test, y5_train, y5_test),\n",
    "    (X6_train, X6_test, y6_train, y6_test),\n",
    "    (X7_train, X7_test, y7_train, y7_test),\n",
    "    (X8_train, X8_test, y8_train, y8_test),\n",
    "    (X9_train, X9_test, y9_train, y9_test),\n",
    "    (X10_train, X10_test, y10_train, y10_test)\n",
    "]\n",
    "\n",
    "# Corregir las matrices de confusiÃ³n para cada modelo\n",
    "for i, (X_train, X_test, y_train, y_test) in enumerate(datos_modelos, start=1):\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_prob = modelo.predict_proba(X_test)[:, 1]  \n",
    "    y_pred_ajustado = ['f' if prob >= 0.3 else 't' for prob in y_pred_prob]  \n",
    "\n",
    "    # Convertir ambas listas a strings\n",
    "    y_test = [str(y) for y in y_test]  \n",
    "    y_pred_ajustado = [str(y) for y in y_pred_ajustado]  \n",
    "\n",
    "    matriz = confusion_matrix(y_test, y_pred_ajustado)\n",
    "    \n",
    "    print(f\"\\n--- Matriz de ConfusiÃ³n Modelo {i} (Umbral=0.3) ---\")\n",
    "    print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test = np.where(y1_test == 'No', 'f', y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases en y1_test: ['0.0' '1.0']\n",
      "Clases en y1_pred: [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Clases en y1_test:\", np.unique(y1_test))\n",
    "print(\"Clases en y1_pred:\", np.unique(y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo 1 - Clases en y_test: ['0.0' '1.0']\n",
      "Modelo 1 - Clases en y_pred: [1]\n",
      "\n",
      "Modelo 2 - Clases en y_test: [0. 1.]\n",
      "Modelo 2 - Clases en y_pred: [1]\n",
      "\n",
      "Modelo 3 - Clases en y_test: [0 1]\n",
      "Modelo 3 - Clases en y_pred: [1]\n",
      "\n",
      "Modelo 4 - Clases en y_test: [0 1]\n",
      "Modelo 4 - Clases en y_pred: [1]\n",
      "\n",
      "Modelo 5 - Clases en y_test: [0. 1.]\n",
      "Modelo 5 - Clases en y_pred: [1]\n",
      "\n",
      "Modelo 6 - Clases en y_test: [0 1]\n",
      "Modelo 6 - Clases en y_pred: [1]\n",
      "\n",
      "Modelo 7 - Clases en y_test: [0 1]\n",
      "Modelo 7 - Clases en y_pred: [1]\n",
      "\n",
      "Modelo 8 - Clases en y_test: [0. 1.]\n",
      "Modelo 8 - Clases en y_pred: [1]\n",
      "\n",
      "Modelo 9 - Clases en y_test: [0 1]\n",
      "Modelo 9 - Clases en y_pred: [1]\n",
      "\n",
      "Modelo 10 - Clases en y_test: [0 1]\n",
      "Modelo 10 - Clases en y_pred: [1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):  # Del Modelo 1 al 10\n",
    "    y_test = globals()[f'y{i}_test']\n",
    "    y_pred = globals()[f'y{i}_pred']\n",
    "    print(f\"\\nModelo {i} - Clases en y_test:\", np.unique(y_test))\n",
    "    print(f\"Modelo {i} - Clases en y_pred:\", np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrecisiÃ³n Modelo 1 (binaria t vs f): 0.0\n",
      "PrecisiÃ³n Modelo 2 (binaria t vs f): 0.0\n",
      "PrecisiÃ³n Modelo 3 (binaria t vs f): 0.0\n",
      "PrecisiÃ³n Modelo 4 (binaria t vs f): 0.0\n",
      "PrecisiÃ³n Modelo 5 (binaria t vs f): 0.0\n",
      "PrecisiÃ³n Modelo 6 (binaria t vs f): 0.0\n",
      "PrecisiÃ³n Modelo 7 (binaria t vs f): 0.0\n",
      "PrecisiÃ³n Modelo 8 (binaria t vs f): 0.0\n",
      "PrecisiÃ³n Modelo 9 (binaria t vs f): 0.0\n",
      "PrecisiÃ³n Modelo 10 (binaria t vs f): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "\n",
    "def precision_binaria(y_true, y_pred, pos_label='t'):\n",
    "    \"\"\"Calcula la precisiÃ³n considerando solo 't' y 'f' (ignora otras clases).\"\"\"\n",
    "    # Filtra solo muestras donde y_true es 't' o 'f'\n",
    "    mask = np.isin(y_true, ['t', 'f'])\n",
    "    y_true_bin = y_true[mask]\n",
    "    y_pred_bin = y_pred[mask]\n",
    "    \n",
    "    # Calcula la precisiÃ³n binaria\n",
    "    return precision_score(y_true_bin, y_pred_bin, average='binary', pos_label=pos_label)\n",
    "\n",
    "# --- Ejemplo de uso para todos los modelos ---\n",
    "for i in range(1, 11):\n",
    "    y_test = globals()[f'y{i}_test']\n",
    "    y_pred = globals()[f'y{i}_pred']\n",
    "    precision = precision_binaria(y_test, y_pred)\n",
    "    print(f'PrecisiÃ³n Modelo {i} (binaria t vs f):', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PrecisiÃ³n Modelo 1 (Micro): 0.0\n",
      "\n",
      "PrecisiÃ³n Modelo 2 (Micro): 0.0\n",
      "\n",
      "PrecisiÃ³n Modelo 3 (Micro): 0.3757062146892655\n",
      "\n",
      "PrecisiÃ³n Modelo 4 (Micro): 0.8983050847457628\n",
      "\n",
      "PrecisiÃ³n Modelo 5 (Micro): 0.0\n",
      "\n",
      "PrecisiÃ³n Modelo 6 (Micro): 0.3531073446327684\n",
      "\n",
      "PrecisiÃ³n Modelo 7 (Micro): 0.8983050847457628\n",
      "\n",
      "PrecisiÃ³n Modelo 8 (Micro): 0.0\n",
      "\n",
      "PrecisiÃ³n Modelo 9 (Micro): 0.3389830508474576\n",
      "\n",
      "PrecisiÃ³n Modelo 10 (Micro): 0.8954802259887006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# AsegÃºrate de que las predicciones y las etiquetas reales estÃ©n en formato de texto (si es necesario)\n",
    "y1_test = [str(y) for y in y1_test]\n",
    "y1_pred = [str(y) for y in y1_pred]\n",
    "y2_test = [str(y) for y in y2_test]\n",
    "y2_pred = [str(y) for y in y2_pred]\n",
    "y3_test = [str(y) for y in y3_test]\n",
    "y3_pred = [str(y) for y in y3_pred]\n",
    "y4_test = [str(y) for y in y4_test]\n",
    "y4_pred = [str(y) for y in y4_pred]\n",
    "y5_test = [str(y) for y in y5_test]\n",
    "y5_pred = [str(y) for y in y5_pred]\n",
    "y6_test = [str(y) for y in y6_test]\n",
    "y6_pred = [str(y) for y in y6_pred]\n",
    "y7_test = [str(y) for y in y7_test]\n",
    "y7_pred = [str(y) for y in y7_pred]\n",
    "y8_test = [str(y) for y in y8_test]\n",
    "y8_pred = [str(y) for y in y8_pred]\n",
    "y9_test = [str(y) for y in y9_test]\n",
    "y9_pred = [str(y) for y in y9_pred]\n",
    "y10_test = [str(y) for y in y10_test]\n",
    "y10_pred = [str(y) for y in y10_pred]\n",
    "\n",
    "# --- Modelo 1 ---\n",
    "precision1 = precision_score(y1_test, y1_pred, average='micro')  # O 'macro', 'weighted'\n",
    "print('\\nPrecisiÃ³n Modelo 1 (Micro):', precision1)\n",
    "\n",
    "# --- Modelo 2 ---\n",
    "precision2 = precision_score(y2_test, y2_pred, average='micro')  # O 'macro', 'weighted'\n",
    "print('\\nPrecisiÃ³n Modelo 2 (Micro):', precision2)\n",
    "\n",
    "# --- Modelo 3 ---\n",
    "precision3 = precision_score(y3_test, y3_pred, average='micro')  # O 'macro', 'weighted'\n",
    "print('\\nPrecisiÃ³n Modelo 3 (Micro):', precision3)\n",
    "\n",
    "# --- Modelo 4 ---\n",
    "precision4 = precision_score(y4_test, y4_pred, average='micro')  # O 'macro', 'weighted'\n",
    "print('\\nPrecisiÃ³n Modelo 4 (Micro):', precision4)\n",
    "\n",
    "# --- Modelo 5 ---\n",
    "precision5 = precision_score(y5_test, y5_pred, average='micro')  # O 'macro', 'weighted'\n",
    "print('\\nPrecisiÃ³n Modelo 5 (Micro):', precision5)\n",
    "\n",
    "# --- Modelo 6 ---\n",
    "precision6 = precision_score(y6_test, y6_pred, average='micro')  # O 'macro', 'weighted'\n",
    "print('\\nPrecisiÃ³n Modelo 6 (Micro):', precision6)\n",
    "\n",
    "# --- Modelo 7 ---\n",
    "precision7 = precision_score(y7_test, y7_pred, average='micro')  # O 'macro', 'weighted'\n",
    "print('\\nPrecisiÃ³n Modelo 7 (Micro):', precision7)\n",
    "\n",
    "# --- Modelo 8 ---\n",
    "precision8 = precision_score(y8_test, y8_pred, average='micro')  # O 'macro', 'weighted'\n",
    "print('\\nPrecisiÃ³n Modelo 8 (Micro):', precision8)\n",
    "\n",
    "# --- Modelo 9 ---\n",
    "precision9 = precision_score(y9_test, y9_pred, average='micro')  # O 'macro', 'weighted'\n",
    "print('\\nPrecisiÃ³n Modelo 9 (Micro):', precision9)\n",
    "\n",
    "# --- Modelo 10 ---\n",
    "precision10 = precision_score(y10_test, y10_pred, average='micro')  # O 'macro', 'weighted'\n",
    "print('\\nPrecisiÃ³n Modelo 10 (Micro):', precision10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exactitud Modelo 1: 0.0\n",
      "\n",
      "Exactitud Modelo 2: 0.0\n",
      "\n",
      "Exactitud Modelo 3: 0.3757062146892655\n",
      "\n",
      "Exactitud Modelo 4: 0.8983050847457628\n",
      "\n",
      "Exactitud Modelo 5: 0.0\n",
      "\n",
      "Exactitud Modelo 6: 0.3531073446327684\n",
      "\n",
      "Exactitud Modelo 7: 0.8983050847457628\n",
      "\n",
      "Exactitud Modelo 8: 0.0\n",
      "\n",
      "Exactitud Modelo 9: 0.3389830508474576\n",
      "\n",
      "Exactitud Modelo 10: 0.8954802259887006\n"
     ]
    }
   ],
   "source": [
    "# Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#exactitud = accuracy_score(y_test, y_pred)\n",
    "#print('Exactitud del modelo:')\n",
    "#print(exactitud)\n",
    "\n",
    "\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculamos la exactitud para cada modelo:\n",
    "\n",
    "# --- Modelo 1 ---\n",
    "exactitud1 = accuracy_score(y1_test, y1_pred)\n",
    "print('\\nExactitud Modelo 1:', exactitud1)\n",
    "\n",
    "# --- Modelo 2 ---\n",
    "exactitud2 = accuracy_score(y2_test, y2_pred)\n",
    "print('\\nExactitud Modelo 2:', exactitud2)\n",
    "\n",
    "# --- Modelo 3 ---\n",
    "exactitud3 = accuracy_score(y3_test, y3_pred)\n",
    "print('\\nExactitud Modelo 3:', exactitud3)\n",
    "\n",
    "# --- Modelo 4 ---\n",
    "exactitud4 = accuracy_score(y4_test, y4_pred)\n",
    "print('\\nExactitud Modelo 4:', exactitud4)\n",
    "\n",
    "# --- Modelo 5 ---\n",
    "exactitud5 = accuracy_score(y5_test, y5_pred)\n",
    "print('\\nExactitud Modelo 5:', exactitud5)\n",
    "\n",
    "# --- Modelo 6 ---\n",
    "exactitud6 = accuracy_score(y6_test, y6_pred)\n",
    "print('\\nExactitud Modelo 6:', exactitud6)\n",
    "\n",
    "# --- Modelo 7 ---\n",
    "exactitud7 = accuracy_score(y7_test, y7_pred)\n",
    "print('\\nExactitud Modelo 7:', exactitud7)\n",
    "\n",
    "# --- Modelo 8 ---\n",
    "exactitud8 = accuracy_score(y8_test, y8_pred)\n",
    "print('\\nExactitud Modelo 8:', exactitud8)\n",
    "\n",
    "# --- Modelo 9 ---\n",
    "exactitud9 = accuracy_score(y9_test, y9_pred)\n",
    "print('\\nExactitud Modelo 9:', exactitud9)\n",
    "\n",
    "# --- Modelo 10 ---\n",
    "exactitud10 = accuracy_score(y10_test, y10_pred)\n",
    "print('\\nExactitud Modelo 10:', exactitud10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistribuciÃ³n en y1_test: Counter({'0.0': 223, '1.0': 131})\n",
      "DistribuciÃ³n en y1_pred: Counter({'1': 354})\n"
     ]
    }
   ],
   "source": [
    "# Verificar la distribuciÃ³n de clases en y_test y y_pred\n",
    "from collections import Counter\n",
    "\n",
    "print(\"DistribuciÃ³n en y1_test:\", Counter(y1_test))\n",
    "print(\"DistribuciÃ³n en y1_pred:\", Counter(y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DistribuciÃ³n en y1_test (real): Counter({'0.0': 223, '1.0': 131})\n",
      "DistribuciÃ³n en y1_pred_ajustado: Counter({'f': 353, 't': 1})\n",
      "\n",
      "Sensibilidad ajustada (Recall para 'f'): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Definir el modelo con balanceo de clases (para manejar desequilibrio)\n",
    "modelo = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Entrenar el modelo con tus datos del Modelo 1\n",
    "modelo.fit(X1_train, y1_train)\n",
    "\n",
    "# Obtener probabilidades para la clase 'f' (asumiento que es la clase minoritaria)\n",
    "y1_pred_prob = modelo.predict_proba(X1_test)[:, 1]  # Probabilidades de la clase 'f'\n",
    "\n",
    "# Ajustar el umbral de decisiÃ³n (empieza con 0.3 y ajusta segÃºn necesidad)\n",
    "umbral = 0.3  # Puedes probar con 0.4, 0.2, etc.\n",
    "y1_pred_ajustado = ['f' if prob >= umbral else 't' for prob in y1_pred_prob]\n",
    "\n",
    "# Verificar distribuciÃ³n de predicciones\n",
    "print(\"\\nDistribuciÃ³n en y1_test (real):\", Counter(y1_test))\n",
    "print(\"DistribuciÃ³n en y1_pred_ajustado:\", Counter(y1_pred_ajustado))\n",
    "\n",
    "# Calcular mÃ©tricas de recall (sensibilidad ajustada)\n",
    "sensibilidad1_ajustada = recall_score(y1_test, y1_pred_ajustado, average='micro', pos_label='f')\n",
    "print(\"\\nSensibilidad ajustada (Recall para 'f'):\", sensibilidad1_ajustada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad ajustada: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Modelo con balanceo de clases\n",
    "modelo = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "modelo.fit(X1_train, y1_train)\n",
    "\n",
    "# Predicciones con umbral ajustado\n",
    "y1_pred_prob = modelo.predict_proba(X1_test)[:, 1]  # Probabilidad de 'f'\n",
    "umbral = 0.3  # Ajusta segÃºn necesidad\n",
    "y1_pred_ajustado = ['f' if prob >= umbral else 't' for prob in y1_pred_prob]\n",
    "\n",
    "# Sensibilidad corregida\n",
    "sensibilidad = recall_score(y1_test, y1_pred_ajustado, average='micro', pos_label='f')\n",
    "print(\"Sensibilidad ajustada:\", sensibilidad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad Modelo 1: 0.0\n",
      "Sensibilidad Modelo 2: 0.0\n",
      "Sensibilidad Modelo 3: 0.0\n",
      "Sensibilidad Modelo 4: 0.0\n",
      "Sensibilidad Modelo 5: 0.0\n",
      "Sensibilidad Modelo 6: 0.0\n",
      "Sensibilidad Modelo 7: 0.0\n",
      "Sensibilidad Modelo 8: 0.0\n",
      "Sensibilidad Modelo 9: 0.0\n",
      "Sensibilidad Modelo 10: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghseb\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1618: UserWarning: Note that pos_label (set to 'f') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from collections import Counter\n",
    "\n",
    "# Listas de datos de entrenamiento y prueba para cada modelo\n",
    "X_train_list = [X1_train, X2_train, X3_train, X4_train, X5_train, X6_train, X7_train, X8_train, X9_train, X10_train]\n",
    "y_train_list = [y1_train, y2_train, y3_train, y4_train, y5_train, y6_train, y7_train, y8_train, y9_train, y10_train]\n",
    "X_test_list = [X1_test, X2_test, X3_test, X4_test, X5_test, X6_test, X7_test, X8_test, X9_test, X10_test]\n",
    "y_test_list = [y1_test, y2_test, y3_test, y4_test, y5_test, y6_test, y7_test, y8_test, y9_test, y10_test]\n",
    "\n",
    "# Umbral ajustado\n",
    "umbral = 0.3\n",
    "\n",
    "# Iterar sobre los modelos\n",
    "for i, (X_train, y_train, X_test, y_test) in enumerate(zip(X_train_list, y_train_list, X_test_list, y_test_list), start=1):\n",
    "    # Crear y entrenar el modelo\n",
    "    modelo = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones con umbral ajustado\n",
    "    y_pred_prob = modelo.predict_proba(X_test)[:, 1]  # Probabilidad de 'f'\n",
    "    y_pred_ajustado = ['f' if prob >= umbral else 't' for prob in y_pred_prob]\n",
    "    \n",
    "    # Calcular sensibilidad\n",
    "    sensibilidad = recall_score(y_test, y_pred_ajustado, average='micro', pos_label='f')\n",
    "    print(f\"Sensibilidad Modelo {i}:\", sensibilidad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**reemplazar los valores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores Ãºnicos en Var_Dep1: [0. 1.]\n",
      "Valores Ãºnicos en Var_Dep2: [0. 1.]\n",
      "Valores Ãºnicos en Var_Dep3: [0 1]\n",
      "Valores Ãºnicos en Var_Dep4: [0 1]\n",
      "Valores Ãºnicos en Var_Dep5: [0. 1.]\n",
      "Valores Ãºnicos en Var_Dep6: [0 1]\n",
      "Valores Ãºnicos en Var_Dep7: [0 1]\n",
      "Valores Ãºnicos en Var_Dep8: [0. 1.]\n",
      "Valores Ãºnicos en Var_Dep9: [0 1]\n",
      "Valores Ãºnicos en Var_Dep10: [0 1]\n"
     ]
    }
   ],
   "source": [
    "#verificar los valores sin repetir\n",
    "#unico=np.unique(df['class'])\n",
    "#unico\n",
    "\n",
    "# Verificar los valores Ãºnicos en las variables dependientes definidas\n",
    "variables_dependientes = [Var_Dep1, Var_Dep2, Var_Dep3, Var_Dep4, Var_Dep5, Var_Dep6, Var_Dep7, Var_Dep8, Var_Dep9, Var_Dep10]\n",
    "\n",
    "for i, var_dep in enumerate(variables_dependientes, start=1):\n",
    "    unico = np.unique(var_dep)\n",
    "    print(f\"Valores Ãºnicos en Var_Dep{i}: {unico}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
